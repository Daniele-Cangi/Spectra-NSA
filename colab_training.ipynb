{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb08ba1",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup & Dependencies (2-3 min)\n",
    "\n",
    "**Note:** The `datasets` package will automatically download the MS MARCO hard negatives dataset (~2-3 GB) during first training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18086e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "pip install -q transformers datasets accelerate scipy torch==2.8.0 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU (should be A100-SXM4-40GB for Colab Pro)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe3c34",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Mount Google Drive & Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e690021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed1226",
   "metadata": {},
   "source": [
    "**âš ï¸ IMPORTANT**: Upload these files to your Google Drive first:\n",
    "- `anomalous_embedding_ultimate.py`\n",
    "- `training_monitor.py` (optional, for enhanced monitoring)\n",
    "\n",
    "Put them in: `/content/drive/MyDrive/anomalous_embedding/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files from Drive to Colab runtime\n",
    "!mkdir -p /content/anomalous\n",
    "!cp /content/drive/MyDrive/anomalous_embedding/anomalous_embedding_ultimate.py /content/anomalous/\n",
    "!cp /content/drive/MyDrive/anomalous_embedding/training_monitor.py /content/anomalous/ 2>/dev/null || echo \"training_monitor.py not found (optional)\"\n",
    "\n",
    "# Change to working directory\n",
    "%cd /content/anomalous\n",
    "\n",
    "# Verify files\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2471bb",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Check Configuration (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show parameter estimation for M456 (default)\n",
    "!python anomalous_embedding_ultimate.py --mode param_estimate --size M456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630402d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Check M700 if you want to try it\n",
    "!python anomalous_embedding_ultimate.py --mode param_estimate --size M700"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f76668",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Start Training - M456 (6-8 hours)\n",
    "\n",
    "**Default configuration:**\n",
    "- Size: M456 (458M params)\n",
    "- Epochs: 3\n",
    "- All components enabled (spectral, anchor64, bridge, matryoshka, angular)\n",
    "- Automatic monitoring every 500 steps\n",
    "- Early stopping enabled\n",
    "- Checkpoints saved in `checkpoints_custom/`\n",
    "\n",
    "**ðŸ“¥ Dataset Download:**\n",
    "The training will automatically download the MS MARCO hard negatives dataset (~2-3 GB) from Hugging Face at first run. This takes 5-10 minutes and happens only once (cached afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a506f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECOMMENDED: Full M456 training (6-8h)\n",
    "!python anomalous_embedding_ultimate.py --mode train --epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bb510",
   "metadata": {},
   "source": [
    "### Alternative: M700 for SOTA (12 hours)\n",
    "\n",
    "**Only if you have time and want maximum performance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4662ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: M700 training (12h, target STS >0.840)\n",
    "# !python anomalous_embedding_ultimate.py --size M700 --mode train --epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b398c",
   "metadata": {},
   "source": [
    "### Quick Test Run (1-2 hours)\n",
    "\n",
    "**For debugging or quick experiments:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick 1-epoch test (1-2h)\n",
    "# !python anomalous_embedding_ultimate.py --mode train --epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc702b05",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Backup Checkpoints to Drive\n",
    "\n",
    "**Run this after training completes or periodically during training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c49bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create backup directory in Drive\n",
    "!mkdir -p /content/drive/MyDrive/anomalous_checkpoints\n",
    "\n",
    "# Copy all checkpoints to Drive\n",
    "!cp -r checkpoints_custom/* /content/drive/MyDrive/anomalous_checkpoints/\n",
    "\n",
    "# List backed up files\n",
    "!ls -lh /content/drive/MyDrive/anomalous_checkpoints/\n",
    "\n",
    "print(\"âœ… Checkpoints backed up to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc3b65",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Evaluation\n",
    "\n",
    "**After training completes, evaluate the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick evaluation with best checkpoint\n",
    "!python anomalous_embedding_ultimate.py --mode eval --checkpoint checkpoints_custom/best_sts.pt\n",
    "\n",
    "# Expected output:\n",
    "# Recall@10: 0.XXX | STS (Spearman): 0.825+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d779b",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Comprehensive Evaluation Suite (Optional)\n",
    "\n",
    "**For detailed benchmarking against SOTA models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999238c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload anomalous_eval_suite.py if you have it\n",
    "!cp /content/drive/MyDrive/anomalous_embedding/anomalous_eval_suite.py /content/anomalous/ 2>/dev/null || echo \"eval suite not found\"\n",
    "\n",
    "# Quick evaluation (subset of data)\n",
    "!python anomalous_eval_suite.py --checkpoint checkpoints_custom/best_sts.pt --size M456 --quick\n",
    "\n",
    "# Full evaluation (takes longer)\n",
    "# !python anomalous_eval_suite.py --checkpoint checkpoints_custom/best_sts.pt --size M456"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2ab6a",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Extract Embeddings (Optional)\n",
    "\n",
    "**Test the model with custom text:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c412d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for custom texts\n",
    "!python anomalous_embedding_ultimate.py \\\n",
    "    --mode extract \\\n",
    "    --checkpoint checkpoints_custom/best_sts.pt \\\n",
    "    --texts \"Quantum mechanics reveals hidden patterns\" \"Machine learning transforms data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ffebc",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Ablation Studies (Optional)\n",
    "\n",
    "**Test individual component contributions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test without spectral attention (1 epoch quick test)\n",
    "# !python anomalous_embedding_ultimate.py --no-spectral --mode train --epochs 1\n",
    "\n",
    "# Test without anchor64\n",
    "# !python anomalous_embedding_ultimate.py --no-anchor64 --mode train --epochs 1\n",
    "\n",
    "# Test minimal configuration (no auxiliary components)\n",
    "# !python anomalous_embedding_ultimate.py --no-spectral --no-anchor64 --no-bridge --no-matry --mode train --epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c845571",
   "metadata": {},
   "source": [
    "## ðŸ“Š Monitor Training Progress\n",
    "\n",
    "**Look for these indicators during training:**\n",
    "\n",
    "### Good Signs âœ…\n",
    "```\n",
    "[MONITOR] STS-B: 0.XXX | Target: 0.825 | Progress: XX.X%\n",
    "[MONITOR] âœ“ New best STS: 0.XXX\n",
    "```\n",
    "\n",
    "### Warning Signs âš ï¸\n",
    "```\n",
    "âš ï¸ Gradient explosion detected\n",
    "âš ï¸ Embedding collapse detected\n",
    "âš ï¸ No improvement (5/5)\n",
    "âš ï¸ EARLY STOPPING TRIGGERED\n",
    "```\n",
    "\n",
    "### Expected Timeline:\n",
    "- **Step 500**: First evaluation, STS ~0.60-0.70\n",
    "- **Step 1000**: STS ~0.75-0.80\n",
    "- **Step 2000**: STS ~0.80-0.82\n",
    "- **End of training**: STS >0.825 (target achieved!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6b294",
   "metadata": {},
   "source": [
    "## ðŸ”§ Troubleshooting\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "\n",
    "If you get OOM errors with M456:\n",
    "\n",
    "1. **Reduce batch size** (edit the config in the .py file):\n",
    "   - Change `batch_train = 32` â†’ `batch_train = 24`\n",
    "   - Or try `batch_train = 16`\n",
    "\n",
    "2. **Use gradient checkpointing** (if available)\n",
    "\n",
    "3. **Switch to M456** if you're trying M700\n",
    "\n",
    "### Training Too Slow\n",
    "\n",
    "Check GPU type:\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "Should show: **A100-SXM4-40GB**\n",
    "\n",
    "If not A100, training will be much slower.\n",
    "\n",
    "### Files Not Found\n",
    "\n",
    "Make sure you uploaded:\n",
    "- `anomalous_embedding_ultimate.py` to `/content/drive/MyDrive/anomalous_embedding/`\n",
    "- (Optional) `training_monitor.py` to the same location\n",
    "\n",
    "### Import Errors\n",
    "\n",
    "Re-run the installation cell:\n",
    "```python\n",
    "!pip install -q transformers datasets accelerate scipy torch --upgrade\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06edf3e",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Success Criteria\n",
    "\n",
    "### M456 (Default)\n",
    "- âœ… STS-B > 0.825 (competitive with BGE-base)\n",
    "- âœ… Training completes <8h on A100\n",
    "- âœ… Fits in Colab Pro (40GB)\n",
    "- âœ… No crashes or OOM\n",
    "\n",
    "### M700 (SOTA Target)\n",
    "- âœ… STS-B > 0.840 (competitive with GTE-large)\n",
    "- âœ… Training completes <12h on A100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31204b68",
   "metadata": {},
   "source": [
    "## ðŸ“ Notes\n",
    "\n",
    "- **Checkpoints** are saved every 2000 steps in `checkpoints_custom/`\n",
    "- **Best model** is saved as `best_sts.pt` when STS improves\n",
    "- **Early stopping** triggers after 5 evaluations without improvement\n",
    "- **Backup regularly** to Google Drive to avoid data loss\n",
    "- **Colab disconnects** after ~12 hours idle - keep the tab open!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1afe76",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸš€ Quick Start Summary\n",
    "\n",
    "**For most users, just run these cells in order:**\n",
    "\n",
    "1. Install dependencies\n",
    "2. Mount Drive\n",
    "3. Copy files\n",
    "4. Start training (M456, 6-8h)\n",
    "5. Backup checkpoints\n",
    "6. Evaluate\n",
    "\n",
    "**Expected result**: STS-B > 0.825 âœ…\n",
    "\n",
    "---\n",
    "\n",
    "**File**: `anomalous_embedding_ultimate.py`\n",
    "\n",
    "**Status**: âœ… Production Ready\n",
    "\n",
    "**Best for**: Colab Pro with A100 40GB\n",
    "\n",
    "ðŸŽ¯ **Ready to train!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
